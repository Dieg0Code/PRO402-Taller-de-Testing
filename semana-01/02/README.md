# ğŸ“š Clase 02: Pruebas de sistema, verificaciÃ³n vs validaciÃ³n y Conceptos de Pruebas Automatizadas

- Unidad 1: **Taller de Calidad y Testing de Software**
- Fecha: Martes 12 de Agosto, 2025
- Horario: 15:50 - 18:10
- Docente: Diego Obando

## ğŸ¯ Objetivos de la Clase

Al finalizar la clase, serÃ¡s capaz de:

- Comprender la diferencia entre verificaciÃ³n y validaciÃ³n.
- Identificar los tipos de pruebas de sistema y su importancia.
- Conocer los conceptos bÃ¡sicos de pruebas automatizadas y su implementaciÃ³n.

## ğŸ“– Contenidos

- VerificaciÃ³n vs ValidaciÃ³n
- Pruebas de Sistema
- IntroducciÃ³n a las Pruebas Automatizadas

## ğŸ“š VerificaciÃ³n vs ValidaciÃ³n

### 1. Definiciones Clave ğŸ§­

- **VerificaciÃ³n (Â¿Construimos el producto correctamente?)**  
  Actividades para comprobar que cada artefacto (requisitos, diseÃ±o, cÃ³digo) cumple con las especificaciones establecidas. Se centra en la CONSISTENCIA interna.
- **ValidaciÃ³n (Â¿Construimos el producto correcto?)**  
  Actividades para confirmar que el software satisface necesidades reales del usuario/negocio en su contexto. Se centra en la ADECUACIÃ“N al uso.

> Mnemonic: VerificaciÃ³n = â€œChecklistsâ€. ValidaciÃ³n = â€œUsuariosâ€.

### 2. Comparativa RÃ¡pida âš–ï¸

| Aspecto         | VerificaciÃ³n ğŸ› ï¸                                                                  | ValidaciÃ³n ğŸ‘¥                                                           |
| --------------- | -------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |
| Pregunta        | Â¿Correcto segÃºn especificaciÃ³n?                                                  | Â¿Ãštil y correcto para el usuario?                                       |
| Momento         | Durante el desarrollo (iterativa)                                                | Al final de un ciclo / antes de liberar                                 |
| QuiÃ©n participa | Devs, QA tÃ©cnico                                                                 | Usuarios, negocio, QA funcional                                         |
| Ejemplos        | RevisiÃ³n de cÃ³digo, inspecciÃ³n de requisitos, anÃ¡lisis estÃ¡tico, tests unitarios | Pruebas de aceptaciÃ³n, pruebas beta, pruebas exploratorias con usuarios |
| Enfoque         | PrevenciÃ³n                                                                       | AceptaciÃ³n / Ajuste                                                     |
| Artefactos base | Documentos y cÃ³digo                                                              | Casos de uso reales, escenarios de negocio                              |

### 3. Ejemplo Integrado (Funcionalidad: Registro de Usuario) ğŸ§ª

| Paso                                                                         | AcciÃ³n                 | Tipo         |
| ---------------------------------------------------------------------------- | ---------------------- | ------------ |
| Revisar que el requisito â€œcontraseÃ±a mÃ­nima 8 caracteresâ€ estÃ© escrito claro | RevisiÃ³n de requisitos | VerificaciÃ³n |
| Code review del mÃ³dulo hashPassword()                                        | Peer review            | VerificaciÃ³n |
| Test unitario: hash no igual a texto plano                                   | Test unitario          | VerificaciÃ³n |
| Test de integraciÃ³n: flujo POST /register crea usuario y envÃ­a email         | IntegraciÃ³n            | VerificaciÃ³n |
| Usuario final prueba registro en entorno preproducciÃ³n con datos reales      | UAT                    | ValidaciÃ³n   |
| Se detecta que el mensaje de Ã©xito es confuso para usuarios                  | Feedback negocio       | ValidaciÃ³n   |

### 4. Errores Comunes ğŸš¨

- Creer que â€œpasar todos los testsâ€ = producto validado.
- Saltarse validaciÃ³n y recibir rechazo tardÃ­o del cliente.
- Hacer â€œvalidaciÃ³nâ€ con el mismo equipo que diseÃ±Ã³ (sesgo).
- No versionar criterios de aceptaciÃ³n (cambian y se pierde trazabilidad).

### 5. RelaciÃ³n con la PirÃ¡mide de Pruebas ğŸ§±

- Base (unitarios/integraciÃ³n): predominio de verificaciÃ³n.
- Capas superiores (sistema / aceptaciÃ³n): foco creciente en validaciÃ³n.
- Necesitamos ambas: solo verificaciÃ³n â†’ software â€œcorrectoâ€ que nadie quiere; solo validaciÃ³n â†’ descubrimos tarde defectos tÃ©cnicos.

### 6. Mini Actividad (3 min) âœï¸

Para cada Ã­tem di V (verificaciÃ³n) o VA (validaciÃ³n):

1. Cliente revisa si el flujo de pago refleja impuestos locales.
2. Linter report detecta variables no usadas.
3. QA funcional ejecuta caso â€œrecuperar contraseÃ±aâ€ con correo real.
4. Equipo hace revisiÃ³n de arquitectura para asegurar estÃ¡ndares internos.

(Resolver en voz / pizarra y justificar una respuesta que genere duda.)

### 7. Checklist PrÃ¡ctico âœ…

Antes de decir â€œlisto para validarâ€:

- [ ] Requisitos revisados (sin ambigÃ¼edades crÃ­ticas)
- [ ] Cobertura de tests bÃ¡sicos aceptable
- [ ] Errores de lint y build resueltos
- [ ] Entorno estable y datos semilla listos
- [ ] Criterios de aceptaciÃ³n documentados

### 8. Frase Resumen ğŸ§ 

Verificar es al â€œcÃ³moâ€ tÃ©cnico lo que validar es al â€œpara quÃ©â€ del usuario.

## Pruebas de Sistema

### 1. Â¿QuÃ© son? ğŸ§©

EjecuciÃ³n de pruebas sobre el **sistema completo integrado** (todas las piezas juntas) para verificar que cumple requisitos funcionales y algunos no funcionales bÃ¡sicos (flujos, datos, mensajes, estados). Responden: â€œÂ¿Las funcionalidades trabajan bien de extremo a extremo bajo condiciones realistas?â€

### 2. Alcance ğŸ”

Incluye: API + lÃ³gica + persistencia + configuraciones + integraciÃ³n con servicios internos simulados (externos reales solo si es ambiente controlado).  
Excluye: detalles internos de funciones (eso es unidad) y feedback final del usuario (eso es aceptaciÃ³n).

### 3. Entradas / Salidas âš™ï¸

| Elemento                | Ejemplos                                                                       |
| ----------------------- | ------------------------------------------------------------------------------ |
| Entradas                | Requisitos funcionales, criterios de aceptaciÃ³n, casos de uso, modelo de datos |
| Artefactos generados    | Casos de prueba E2E, evidencias (capturas/logs), reporte de defectos           |
| OrÃ¡culos (quÃ© comparar) | Respuesta HTTP, cambios en BD, correos enviados (simulados), logs              |

### 4. Tipos comunes dentro de â€œSistemaâ€ ğŸ—‚ï¸

- Funcionales endâ€‘toâ€‘end (flujo completo: registro â†’ login â†’ acciÃ³n).
- De regresiÃ³n (conjunto estable tras cada release).
- Smoke / sanity (subset rÃ¡pido: â€œel sistema respiraâ€).
- ConfiguraciÃ³n / despliegue (variables de entorno correctas, rutas accesibles).
- BÃ¡sicas no funcionales iniciales (tiempo respuesta simple, tamaÃ±o payload).

### 5. Ejemplo (AplicaciÃ³n de Cursos) ğŸ“

Flujo: â€œEstudiante se registra a un curso pagoâ€.

1. PrecondiciÃ³n: Curso â€œJS-101â€ existe con cupos.
2. Pasos: (a) Registrar usuario, (b) Login, (c) Seleccionar curso, (d) Confirmar inscripciÃ³n.
3. Verificaciones:
   - HTTP 201 al crear usuario, hash password â‰  texto.
   - En BD: registro en tabla inscripciones con estado â€œpendienteâ€.
   - Email simulado (mock SMTP) generado.
   - Cupos decrementan en 1.
4. Resultado esperado: Estado final â€œinscritoâ€.

### 6. Estrategia mÃ­nima para el curso ğŸ§­

Semana 2â€“3:

- Definir â€œsmoke listâ€ (5â€“7 flujos principales).
- Automatizar progresivamente algunos como pruebas de integraciÃ³n de alto nivel (no UI grÃ¡fica aÃºn).
- Mantener datos de prueba semilla (reset reproducible).

### 7. Diferencias: Unidad vs IntegraciÃ³n vs Sistema ğŸ”„

| Aspecto     | Unidad           | IntegraciÃ³n          | Sistema                      |
| ----------- | ---------------- | -------------------- | ---------------------------- |
| Aislamiento | MÃ¡ximo (mocks)   | Parcial              | MÃ­nimo (real)                |
| Velocidad   | Muy alta         | Media                | MÃ¡s lenta                    |
| Objetivo    | Correcto interno | ColaboraciÃ³n mÃ³dulos | Flujo completo y requisitos  |
| Fragilidad  | Baja             | Media                | Alta si no se diseÃ±a estable |

### 8. Datos de Prueba ğŸ—ƒï¸

Principios:

- Reutilizables: script para poblar / limpiar (seed + reset).
- Representativos: incluir casos lÃ­mite (cupo=1, usuario duplicado).
- Desacoplados de datos personales reales (ficticios siempre).
  Formato sugerido: carpeta /data con JSON semilla.

### 9. Ambientes ğŸŒ

| Ambiente           | Uso                   | Riesgo si falta             |
| ------------------ | --------------------- | --------------------------- |
| DEV                | Desarrollo diario     | Mezcla parcial de cÃ³digo    |
| TEST / QA          | Pruebas de sistema    | Datos inconsistentes        |
| STAGING (opcional) | Ensayo preâ€‘producciÃ³n | Saltar validaciones finales |
| PROD               | Real                  | No es para experimentar     |

Para la asignatura: trabajaremos con un ambiente local (simulando TEST) + mÃ¡s adelante integraciÃ³n remota simple.

### 10. Errores frecuentes âš ï¸

- Duplicar casos (mismo flujo con texto distinto).
- Tests de sistema demasiado dependientes del momento del dÃ­a.
- No controlar estado inicial â†’ falsos positivos/negativos.
- Probar â€œtodoâ€ en un solo caso gigante (difÃ­cil de diagnosticar).
- Usar credenciales reales (riesgo privacidad).

### 11. Buenas prÃ¡cticas âœ…

- Nombrar casos por objetivo: ST_REGISTRO_USUARIO_OK.
- 1 flujo principal + variaciones separadas (ej: contraseÃ±a corta).
- Evidencia automÃ¡tica: logs guardados / capturas si UI (mÃ¡s adelante).
- Definir criterio â€œpasa/fallaâ€ claro antes de ejecutar.
- Mantener suite smoke < 5 min.

### 12. Mini Actividad (5 min) âœï¸

DiseÃ±a esquema (sin cÃ³digo) de un test de sistema para â€œRecuperar contraseÃ±aâ€:
Incluye: precondiciÃ³n, pasos, verificaciones y datos clave. Compartir 1 ejemplo en voz.

### 13. Checklist antes de ejecutar suite de sistema ğŸ“‹

- [ ] Base de datos reseteada / datos conocidos.
- [ ] Variables de entorno cargadas (.env ejemplo).
- [ ] Servicios dependientes simulados o disponibles.
- [ ] Logs limpios (fÃ¡cil detectar nuevo error).
- [ ] Lista de casos priorizada (crit â†’ opt).

### 14. MÃ©trica inicial sugerida ğŸ“Š

Tiempo total suite smoke / NÂº de defectos reales detectados / NÂº falsos positivos â†’ Usar para ajustar cobertura.

### 15. Frase memoria ğŸ§ 

â€œPrueba de sistema = realidad controlada: todo junto, pero bajo un guiÃ³n verificable.â€

> Siguiente secciÃ³n: IntroducciÃ³n a las Pruebas Automatizadas (por quÃ©, quÃ© NO automatizar primero, y vistazo a Jest).

## IntroducciÃ³n a las Pruebas Automatizadas

### 0. Panorama RÃ¡pido ğŸ—ºï¸

Automatizar = convertir verificaciones repetibles (entradas, ejecuciÃ³n, comparaciÃ³n con esperado) en scripts que corren solos y entregan un veredicto (pasa / falla) consistente y rÃ¡pido.

### Conceptos Clave (Glosario Inicial) ğŸ”‘

| TÃ©rmino                   | ExplicaciÃ³n breve                                                                                    |
| ------------------------- | ---------------------------------------------------------------------------------------------------- |
| Test Runner               | Herramienta que localiza, ejecuta y reporta tests (Jest).                                            |
| Suite                     | Grupo de tests relacionados (bloque describe).                                                       |
| Caso de prueba            | Escenario individual (bloque test / it).                                                             |
| AserciÃ³n (assert)         | VerificaciÃ³n: expect(valor).matcher(esperado).                                                       |
| Matcher                   | MÃ©todo que compara (toBe, toEqual, toThrow, etc.).                                                   |
| Fixture                   | Datos / estado inicial controlado para un test.                                                      |
| Mock                      | Objeto/funciÃ³n simulada que reemplaza dependencia real (controla comportamiento + captura llamadas). |
| Stub                      | VersiÃ³n mÃ­nima que devuelve respuestas predefinidas (no siempre inspeccionada).                      |
| Spy                       | Observa/espÃ­a una funciÃ³n real (registra llamadas) sin reemplazar lÃ³gica (o con envoltorio).         |
| Cobertura (coverage)      | % de cÃ³digo ejecutado por tests (lÃ­neas, ramas, funciones).                                          |
| Flaky Test                | Test que a veces pasa y a veces falla sin cambios de cÃ³digo (inestable).                             |
| Determinismo              | Misma entrada â†’ mismo resultado siempre (ideal para tests).                                          |
| Watch Mode                | Re-ejecuta tests al guardar archivos.                                                                |
| CI (IntegraciÃ³n Continua) | Servidor que ejecuta tests automÃ¡ticamente en cada cambio (pipeline).                                |

### Manual vs Automatizado âš–ï¸

| Aspecto            | Manual                          | Automatizado               |
| ------------------ | ------------------------------- | -------------------------- |
| Velocidad          | Lenta, depende de la persona    | RÃ¡pida y paralelizable     |
| Consistencia       | Variable (cansancio, omisiones) | Repetible idÃ©ntico         |
| Escalabilidad      | Se vuelve costoso               | Escala con infraestructura |
| Costo inicial      | Bajo                            | Mayor (config + escribir)  |
| DetecciÃ³n temprana | Limitada                        | Alta (cada commit)         |

### Flujo TÃ­pico (Ciclo Simplificado) ğŸ”„

1. Especificar comportamiento esperado (quÃ© debe pasar).
2. Escribir test (rojo: falla).
3. Implementar / ajustar cÃ³digo (verde: pasa).
4. Refactor (mantener verde).
5. Integrar a CI (verificar en cada push).
6. Monitorear: eliminar flaky, revisar cobertura relevante (no perseguir 100% ciego).

```
EspecificaciÃ³n â†’ Test rojo â†’ ImplementaciÃ³n â†’ Test verde â†’ Refactor â†’ CI
```

### Buen Alcance Inicial âœ…

- Funciones puras (sin red, sin fechas no controladas).
- Reglas de negocio con condiciones.
- Utilidades crÃ­ticas (cÃ¡lculos, validaciones).
  (No iniciar por UI compleja o integraciones externas inestables.)

### Antipatrones Tempranos âŒ

- Test duplicado (misma verificaciÃ³n con distinto texto).
- Test que solo hace console.log (sin expect).
- Aserciones mÃºltiples sin relaciÃ³n (dificulta causa raÃ­z).
- Uso de tiempos (setTimeout largo) para â€œesperarâ€ algo en vez de simularlo.

### 1. Â¿QuÃ© es una prueba automatizada? âš™ï¸

Script que ejecuta cÃ³digo de la aplicaciÃ³n con entradas controladas y verifica salidas (asserts) de forma repetible sin intervenciÃ³n humana.

### 2. Â¿Por quÃ© automatizar? ğŸ¯

- Repetibilidad (mismo resultado hoy y maÃ±ana).
- Velocidad (segundos vs minutos manuales).
- DetecciÃ³n temprana de regresiones.
- DocumentaciÃ³n viva del comportamiento.
- Base para IntegraciÃ³n Continua (CI).

### 3. Â¿QuÃ© NO automatizar primero? ğŸš«

- Flujos UI inestables / en constante cambio.
- Casos extremadamente raros (baja frecuencia + alto costo).
- Pruebas que dependen de servicios externos sin mocks.
- Rendimiento profundo (requiere tooling especÃ­fico).

Empieza por: funciones puras crÃ­ticas + flujos â€œfelicesâ€ (happy path) de negocio.

### 4. Criterios de selecciÃ³n inicial âœ…

| Pregunta                                       | Si â€œSÃ­â€ â†’ Mejor candidato |
| ---------------------------------------------- | ------------------------- |
| Â¿Corre rÃ¡pido?                                 | âœ”                         |
| Â¿Se usa mucho?                                 | âœ”                         |
| Â¿Romperlo causa daÃ±o visible?                  | âœ”                         |
| Â¿Tiene lÃ³gica (condiciones) que puede cambiar? | âœ”                         |

### 5. ROI simplificado ğŸ’°

Costo inicial alto (escribir + configurar), pero coste marginal â‰ˆ 0 por cada re-ejecuciÃ³n. Manual: coste lineal cada vez. Punto de equilibrio cuando las repeticiones superan el tiempo de creaciÃ³n.

### 6. DÃ³nde encaja en la pirÃ¡mide ğŸ§±

- Base automatizada: unitarios + integraciÃ³n ligera.
- Media: pruebas de sistema automatizadas (selectivas).
- Pico mÃ­nimo: UI endâ€‘toâ€‘end crÃ­ticos (checkout, login).

### 7. Estructura tÃ­pica (Jest) ğŸ§ª

(No instalamos aÃºn, solo concepto.)

```javascript
// archivo: suma.test.js
describe("suma()", () => {
  test("suma dos nÃºmeros positivos", () => {
    expect(suma(2, 3)).toBe(5);
  });

  test("suma con cero", () => {
    expect(suma(7, 0)).toBe(7);
  });
});
```

Palabras clave:

- describe: agrupa casos.
- test / it: define un caso.
- expect(...).matcher: aserciÃ³n (toBe, toEqual, etc.).

### 8. Buenas prÃ¡cticas iniciales ğŸ§­

- 1 idea por test (un assert principal claro).
- Nombres expresivos: â€œdeberÃ­a â€¦â€.
- Evitar dependencias entre tests.
- Preparar datos dentro del test (o helpers simples).
- Mantener tests rÃ¡pidos (< 200 ms cada uno en esta etapa).

### 9. Errores frecuentes al empezar âš ï¸

- Tests que dependen del orden de ejecuciÃ³n.
- Olvidar el assert (el test siempre â€œpasaâ€).
- Verificar demasiadas cosas a la vez.
- Confundir lÃ³gica de producciÃ³n dentro del test (duplicas bugs).

### 10. Mini Showcase (conceptual) ğŸ”

FunciÃ³n objetivo:

```javascript
// src/esPar.js
function esPar(n) {
  if (typeof n !== "number") throw new Error("Tipo invÃ¡lido");
  return n % 2 === 0;
}
module.exports = esPar;
```

Test pensado:

```javascript
// tests/esPar.test.js
const esPar = require("../src/esPar");

describe("esPar", () => {
  test("true para nÃºmero par", () => {
    expect(esPar(4)).toBe(true);
  });
  test("false para nÃºmero impar", () => {
    expect(esPar(7)).toBe(false);
  });
  test("lanza error para string", () => {
    expect(() => esPar("4")).toThrow("Tipo invÃ¡lido");
  });
});
```

Conceptos: caso normal, borde, error.

### 11. Actividad RÃ¡pida (5 min) âœï¸

DiseÃ±a en papel los casos (solo tÃ­tulos) para testear una funciÃ³n `calcularDescuento(precio, porcentaje)`:

- Lista mÃ­nima de 4 casos (incluye error/validaciÃ³n).
- Elegir 1 como â€œprioridad altaâ€ y justificar.

### 12. Checklist previa a automatizar ğŸ§¾

- [ ] FunciÃ³n estable (no cambia cada hora).
- [ ] Requisitos claros (resultado esperado definido).
- [ ] Entradas y salidas deterministas.
- [ ] No depende de red / tiempo real sin control.

Frase cierre: â€œAutomatizar temprano lo estable, manual donde aÃºn exploramos.â€
