# ğŸ“š Clase 03: Software Testeado vs No Testeado, Casos Reales: Fallos famosos por falta de Testing

- Unidad 1: **Taller de Calidad y Testing de Software**
- Fecha: MiÃ©rcoles 13 de Agosto, 2025
- Horario: 15:50 - 18:10
- Docente: Diego Obando

## ğŸ¯ Objetivos de la Clase

Al finalizar la clase, serÃ¡s capaz de:

- Comprender la importancia de las pruebas en el desarrollo de software.
- Identificar casos reales de fallos en software debido a la falta de testing.
- Analizar y discutir lecciones aprendidas de fallos famosos.

## ğŸ“– Contenidos

- Importancia de las pruebas en el desarrollo de software.
- Casos reales de fallos en software por falta de testing.
- Lecciones aprendidas de fallos famosos.

## Software Testeado vs No Testeado

### 1. Idea Central ğŸ§ 

Un sistema â€œfuncionaâ€ no significa que sea confiable. La diferencia real se nota cuando:

- Cambias cÃ³digo â†’ Â¿Sigue comportÃ¡ndose igual? (regresiÃ³n)
- Escala el uso â†’ Â¿Responde de forma estable?
- Ocurre un error â†’ Â¿Lo detectas pronto o el usuario te avisa?

### 2. Contraste RÃ¡pido âš–ï¸

| Aspecto                                | Software Testeado              | Software No Testeado       |
| -------------------------------------- | ------------------------------ | -------------------------- |
| Cambios pequeÃ±os                       | Confianza (suite verde)        | Miedo a romper algo        |
| Bugs reportados por usuarios           | Menos y mÃ¡s especÃ­ficos        | Muchos y repetidos         |
| Refactor                               | HÃ¡bito saludable               | Postergado indefinidamente |
| DocumentaciÃ³n de comportamiento        | Tests vivos                    | Memoria tribal             |
| Tiempo de incorporaciÃ³n de nuevos devs | Corto (lean en tests)          | Largo (depende de â€œgurÃºâ€)  |
| Coste de defectos                      | Descubiertos temprano (barato) | Tarde en prod (caro)       |

### 3. Coste del Defecto ğŸ’¸ (Regla empÃ­rica)

Corrigiendo en:

- DiseÃ±o: barato (1x)
- Desarrollo: 5x
- Pruebas internas: 10x
- ProducciÃ³n: 30xâ€“100x (marca, soporte, parches urgentes)

VisualÃ­zalo: cada dÃ­a sin detectar un defecto crÃ­tico lo â€œcapitalizaâ€ (crece su costo).

### 4. SÃ­ntomas de Proyecto â€œNo Testeadoâ€ ğŸš¨

- Commits grandes y nocturnos (â€œarreglÃ© varias cosasâ€).
- â€œFunciona en mi mÃ¡quinaâ€.
- Bugs que vuelven (regresiones circulares).
- Deuda tÃ©cnica invisible (nadie se atreve a tocar mÃ³dulos viejos).
- Issue tracker lleno de reproducir-pedir-clarificar.

### 5. SÃ­ntomas de Proyecto â€œSaludableâ€ ğŸ©º

- Commits pequeÃ±os + mensajes claros.
- IntegraciÃ³n frecuente (pull/push diario).
- Refactors acompaÃ±ados de tests que validan.
- Defectos nuevos: se aÃ­slan rÃ¡pido y generan tests adicionales.
- MÃ©tricas mÃ­nimas visibles (build status verde).

### 6. Matriz de Riesgo Simplificada ğŸ¯

| MÃ³dulo           | Impacto si falla | Cambia seguido | Â¿Debe priorizar tests?  |
| ---------------- | ---------------- | -------------- | ----------------------- |
| AutenticaciÃ³n    | Alto             | Medio          | SÃ­ (unit + integraciÃ³n) |
| Reportes PDF     | Medio            | Bajo           | Cobertura bÃ¡sica        |
| EnvÃ­o Email      | Medio            | Alto           | Tests + mocks           |
| PÃ¡gina Marketing | Bajo             | Alto           | Manual + smoke ligero   |

Enfoque: primero Alta combinaciÃ³n (Impacto Alto + Cambios Frecuentes).

### 7. Mini Autoâ€‘DiagnÃ³stico (3 preguntas) ğŸ”

Responde S / N:

1. Â¿Puedo modificar una funciÃ³n y saber en <30s si rompÃ­ algo?
2. Â¿Cada bug corregido genera al menos 1 test nuevo?
3. Â¿La mayorÃ­a de defectos se detectan antes de producciÃ³n?

Resultados:

- 3 â€œSÃ­â€: Buen camino.
- 1â€“2 â€œSÃ­â€: Riesgo medio â†’ priorizar suite base.
- 0 â€œSÃ­â€: Urgente establecer pruebas unitarias mÃ­nimas.

### 8. Ejemplo Ilustrativo (FunciÃ³n de cÃ¡lculo impuestos) ğŸ§ª

Escenario:

- VersiÃ³n sin tests: cambio tasa IVA; se rompe cÃ¡lculo descuentos acumulados (nadie lo nota 3 semanas).
- VersiÃ³n con tests: suite falla al cambiar tasa; ajustas lÃ³gica en minutos.

Mensaje: Los tests no evitan pensar, evitan olvidar.

### 9. Mitos Comunes ğŸ§µ

| Mito                                  | Realidad                                  |
| ------------------------------------- | ----------------------------------------- |
| â€œQuita tiempoâ€                        | Ahorra tiempo neto al reducir re-trabajo  |
| â€œSolo para proyectos grandesâ€         | Es lo que permite que crezcan             |
| â€œEl QA se encargaâ€                    | Calidad es responsabilidad colectiva      |
| â€œ100% cobertura = perfectoâ€           | MÃ©trica complementaria, no objetivo Ãºnico |
| â€œPrimero terminamos, luego testeamosâ€ | â€œLuegoâ€ casi nunca llega                  |

### 10. Estrategia de Entrada (lo que haremos en el mÃ³dulo) ğŸ› ï¸

1. Semana 1â€“2: Base de tests unitarios (Jest) en funciones puras.
2. Semana 3: IntegraciÃ³n ligera (mÃ³dulos que colaboran).
3. Semana 4: IntroducciÃ³n a pruebas de sistema controladas.
4. Continuo: AÃ±adir test por cada bug detectado (anti-regresiÃ³n).

### 11. Actividad RÃ¡pida (5 min) âœï¸

En parejas: Elegir un mÃ³dulo hipotÃ©tico (ej: carrito, login, pagos). Listar:

- 2 riesgos (quÃ© podrÃ­a fallar y dolerÃ­a).
- 2 tests mÃ­nimos que mitigarÃ­an cada riesgo.
  Compartir 1 ejemplo al grupo.

### 12. Frase Ancla ğŸ§ 

â€œSoftware sin tests no es â€˜mÃ¡s rÃ¡pidoâ€™; solo difiere el momento en que pagas el costo.â€

## Casos Reales: Fallos (y un Ã©xito) Famosos ğŸ›°ï¸ğŸ’¥

> Objetivo: ver impacto real de defectos y quÃ© prÃ¡ctica de calidad/testing faltÃ³ (o funcionÃ³).

### 1. Ariane 5 â€“ Vuelo 501 (1996) ğŸš€

- Contexto: Cohete europeo (primera misiÃ³n).
- Fallo: ConversiÃ³n de un nÃºmero de 64 bits a 16 bits â†’ overflow â†’ apagado de la unidad inercial â†’ autodestrucciÃ³n.
- Causa raÃ­z: Reuso de cÃ³digo de Ariane 4 sin validar nuevas condiciones de velocidad horizontal.
- QuÃ© faltÃ³: Testing / simulaciones con perfiles reales de vuelo de Ariane 5 + manejo de errores seguro.
- LecciÃ³n: Reuso â‰  copiar y pegar; validar supuestos en nuevo contexto.

### 2. Mars Climate Orbiter (1999) ğŸª

- Fallo: PÃ©rdida de la sonda (se desintegrÃ³ en la atmÃ³sfera marciana).
- Causa: Mezcla de unidades (librasâ€‘fuerza vs newtons) entre equipos (imperial vs mÃ©trico).
- QuÃ© faltÃ³: Validaciones automÃ¡ticas de unidades + pruebas de integraciÃ³n entre subsistemas de navegaciÃ³n.
- LecciÃ³n: â€œPequeÃ±asâ€ inconsistencias de datos destruyen proyectos multimillonarios.

### 3. Theracâ€‘25 (1985â€“87) â˜¢ï¸

- Fallo: MÃºltiples sobredosis de radiaciÃ³n a pacientes.
- Causas: Concurrencia/race conditions, falta de interlocks hardware, confianza excesiva en software â€œoptimizadoâ€.
- QuÃ© faltÃ³: Testing de estrÃ©s concurrente, anÃ¡lisis formal, validaciÃ³n independiente de seguridad.
- LecciÃ³n: En sistemas crÃ­ticos, pruebas negativas y de condiciones de carrera son obligatorias.

### 4. Knight Capital (2012) ğŸ’¸

- Fallo: Algoritmo bursÃ¡til fuera de control â†’ pÃ©rdidas â‰ˆ 440 M USD en 45 minutos.
- Causa: CÃ³digo antiguo reactivado en algunos servidores + despliegue inconsistente.
- QuÃ© faltÃ³: Pruebas de despliegue, feature flags controlados, entorno staging representativo.
- LecciÃ³n: Testing tambiÃ©n incluye proceso de release; consistencia ambiental es crÃ­tica.

### 5. Heartbleed (2014) ğŸ”“

- Fallo: Vulnerabilidad en OpenSSL permitÃ­a leer memoria sensible.
- Causa: Falta de pruebas que cubrieran lÃ­mites y validaciÃ³n de longitud declarada vs real.
- QuÃ© faltÃ³: Tests de seguridad (fuzzing), revisiÃ³n de cÃ³digo exhaustiva en paths crÃ­ticos.
- LecciÃ³n: Casos borde y validaciÃ³n de parÃ¡metros no son opcionales en librerÃ­as base.

### 6. Apollo 11 â€œ1201 / 1202â€ (1969) âœ… (Ã‰xito por buen diseÃ±o)

- Evento: Alarmas de sobrecarga de la computadora de abordo durante alunizaje.
- Causa: Entrada extra de radar saturÃ³ ciclos de CPU.
- QuÃ© funcionÃ³: Sistema priorizaba tareas crÃ­ticas y descartaba las no esenciales (testing + diseÃ±o de prioridades).
- LecciÃ³n: Calidad no solo evita fallos; prepara al sistema para fallar con gracia (resiliencia).

### Patrones Repetidos ğŸ”

| PatrÃ³n                              | Ejemplos       | PrÃ¡ctica que faltÃ³                  |
| ----------------------------------- | -------------- | ----------------------------------- |
| Supuestos no reevaluados            | Ariane 5       | Pruebas con nuevos perfiles         |
| IntegraciÃ³n deficiente              | Mars Orbiter   | ValidaciÃ³n de interfaces / unidades |
| Concurrencia ignorada               | Theracâ€‘25      | Tests de carrera / anÃ¡lisis formal  |
| Release caÃ³tico                     | Knight Capital | Pipeline controlado / rollback      |
| ValidaciÃ³n insuficiente de entradas | Heartbleed     | Tests de lÃ­mites / fuzzing          |

### Lecciones Transversales ğŸ“Œ

1. Reuso exige revalidar supuestos.
2. Datos / unidades deben ser verificados automÃ¡ticamente.
3. Testing de â€œcasos felicesâ€ no basta: hay que buscar fallos.
4. AutomatizaciÃ³n del proceso de despliegue reduce riesgos humanos.
5. DiseÃ±o + pruebas orientadas a resiliencia salvan misiones (Apollo 11).

### Actividad RÃ¡pida (5 min) âœï¸

Elige 1 caso: escribe (a) riesgo principal, (b) test o control que lo habrÃ­a detectado antes. Compartir.

Frase ancla: â€œLos fallos famosos no son magia: son supuestos sin test que llegaron a producciÃ³n.â€
